## Description
The purpose of this repository is to summarise some of Offline RL's research to help build a knowledge framework for beginners in this topic (partly referenced [hanjuku-kaso/awesome-offline-rl](https://github.com/hanjuku-kaso/awesome-offline-rl))

## Reinforcement Learning Primer
- [Notes on Reinforcement Learning Theory](https://github.com/elated-sawyer/Offline-RL-Tutorial/blob/master/materials/Notes_on_Reinforcement_Learning_Theory.pdf) (ongoing)
	- Siyu Zhou

## Papers
### Review/Survey/Position Papers
- [A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems](https://arxiv.org/abs/2203.01387)
	- Rafael Figueiredo Prudencio, Marcos R. O. A. Maximo, and Esther Luna Colombini. arXiv, 2022.
- [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/abs/2005.01643)
	- Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu. arXiv, 2020.
### Offline RL: Theory/Methods
- [BCQ] [Off-Policy Deep Reinforcement Learning without Exploration](http://proceedings.mlr.press/v97/fujimoto19a.html)
	- Scott Fujimoto, David Meger, and Doina Precup. ICML, 2019.
- [BEAR] [Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction](https://papers.nips.cc/paper/2019/hash/c2073ffa77b5357a498057413bb09d3a-Abstract.html) [[website](https://sites.google.com/view/bear-off-policyrl)] [[blog](https://bair.berkeley.edu/blog/2019/12/05/bear/)] [[code](https://github.com/aviralkumar2907/BEAR)]
	- Aviral Kumar, Justin Fu, George Tucker, and Sergey Levine. NeurIPS, 2019.
- [CQL] [Conservative Q-Learning for Offline Reinforcement Learning](https://papers.nips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html) [[website](https://sites.google.com/view/cql-offline-rl)] [[code](https://github.com/aviralkumar2907/CQL)] [[blog](https://bair.berkeley.edu/blog/2020/12/07/offline/)]
	- Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine. NeurIPS, 2020.
### Offline RL: Benchmarks/Experiments
- [D4RL: Datasets for Deep Data-Driven Reinforcement Learning](https://arxiv.org/abs/2004.07219) [[website](https://sites.google.com/view/d4rl/home)] [[blog](https://bair.berkeley.edu/blog/2020/06/25/D4RL/)] [[code](https://github.com/rail-berkeley/d4rl)]
	- Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine. arXiv, 2020.
- [d3rlpy: An Offline Deep Reinforcement Learning Library](https://arxiv.org/abs/2111.03788) [[software](https://github.com/takuseno/d3rlpy)]
	- Takuma Seno and Michita Imai. arXiv, 2021.
### Offline RL: Applications
<!--- 
Off-Policy Evaluation and Learning: Theory/Methods
Off-Policy Evaluation: Contextual Bandits
Off-Policy Evaluation: Reinforcement Learning
Off-Policy Learning
Off-Policy Evaluation and Learning: Benchmarks/Experiments
Off-Policy Evaluation and Learning: Applications
Wrap text --->
## Open Source Software/Implementations
## Blog
## Tutorials/Talks/Lectures
- [Offline Reinforcement Learning: From Algorithms to Practical Challenges](https://sites.google.com/view/offlinerltutorial-neurips2020/home) [[NeurIPS 2020 Offline RL Tutorial Colab Exercise](https://colab.research.google.com/drive/1vO0BipQApzrDSPeChHK1rBsqeRh2rH1m?usp=sharing)]
	- Aviral Kumar and Sergey Levine. NeurIPS2020.
- [Introduction on Offline RL - Zhihu](https://zhuanlan.zhihu.com/p/489470062)



